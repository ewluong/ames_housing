{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Import train and test data\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 76)\n",
      "(1459, 75)\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with too many missing values in the train and test data\n",
    "threshold = 0.4 # set threshold to 50% of missing values\n",
    "dropped_columns = train_data.columns[train_data.isna().mean() > threshold] # get the names of the columns to drop\n",
    "train_data = train_data.drop(dropped_columns, axis=1)\n",
    "test_data = test_data.drop(dropped_columns, axis=1)\n",
    "\n",
    "# Confirm that the desired columns have been dropped\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GarageType      81\n",
      "GarageFinish    81\n",
      "GarageQual      81\n",
      "GarageCond      81\n",
      "BsmtExposure    38\n",
      "                ..\n",
      "BsmtFinSF2       0\n",
      "BsmtUnfSF        0\n",
      "TotalBsmtSF      0\n",
      "MSSubClass       0\n",
      "SalePrice        0\n",
      "Length: 76, dtype: int64\n",
      "GarageFinish     78\n",
      "GarageQual       78\n",
      "GarageCond       78\n",
      "GarageType       76\n",
      "BsmtCond         45\n",
      "                 ..\n",
      "MSSubClass        0\n",
      "Heating           0\n",
      "HeatingQC         0\n",
      "CentralAir        0\n",
      "SaleCondition     0\n",
      "Length: 75, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute median values into the missing data in the numeric columns of the train and test data\n",
    "num_cols = test_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "train_data[num_cols] = train_data[num_cols].fillna(train_data[num_cols].median())\n",
    "test_data[num_cols] = test_data[num_cols].fillna(test_data[num_cols].median())\n",
    "\n",
    "# Confirm that missing values have been imputed\n",
    "print(train_data.isnull().sum().sort_values(ascending=False))\n",
    "print(test_data.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dropna(inplace=True)\n",
    "test_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 76)\n",
      "(1319, 75)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separate the train_data into training and validation sets\n",
    "X = train_data.drop(['SalePrice'], axis=1) # features\n",
    "y = train_data['SalePrice'] # target variable\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070, 75) (1070,)\n",
      "(268, 75) (268,)\n"
     ]
    }
   ],
   "source": [
    "# Check the training and validation subsets\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the column transformer\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
       "                                                  Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
       "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'Ha...\n",
       "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
       "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
       "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
       "       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'SaleType', 'SaleCondition'],\n",
       "      dtype='object'))])),\n",
       "                ('regressor', LinearRegression())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the validation data\n",
    "y_val_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 636248400.175131\n",
      "R2: 0.851312774417597\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using R2 and MSE\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Pipeline\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Define the hyperparameter grid to search over\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [10, 20, 30]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data using the best estimator\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_val_pred = best_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 711596588.0487593\n",
      "R2: 0.8337043796389103\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using R2 and MSE\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# Define hyperparameters for the regressor\n",
    "param_grid = {\n",
    "    'regressor__learning_rate': [0.1, 0.01, 0.001],\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__max_depth': [2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data using the best estimator\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_pred = best_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 612019954.7508689\n",
      "R2: 0.856974808820067\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using R2 and MSE\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', SVR())\n",
    "])\n",
    "\n",
    "# Define hyperparameters for the regressor\n",
    "param_grid = {\n",
    "    'regressor__kernel': ['linear', 'rbf', 'poly'],\n",
    "    'regressor__C': [0.1, 1, 10],\n",
    "    'regressor__gamma': ['scale', 'auto']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data using the best estimator\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_val_pred = best_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1388168369.1683474\n",
      "R2: 0.6755938350554955\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using R2 and MSE\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', ElasticNet())\n",
    "])\n",
    "\n",
    "# Define hyperparameters for the regressor\n",
    "param_grid = {\n",
    "    'regressor__alpha': [0.1, 1, 10],\n",
    "    'regressor__l1_ratio': [0.1, 0.5, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data using the best estimator\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_val_pred = best_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 745704485.9976237\n",
      "R2: 0.8257335796886576\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using R2 and MSE\n",
    "\n",
    "mse = mean_squared_error(y_val, y_val_pred)\n",
    "r2 = r2_score(y_val, y_val_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like Gradient Boosting was the best method, let's try it with a PCA analysis before the gradient boosting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA & Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('pca', TruncatedSVD()),\n",
    "    ('regressor', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# Define hyperparameters for the pipeline\n",
    "param_grid = {\n",
    "    'pca__n_components': [10, 20, 30],\n",
    "    'regressor__n_estimators': [100, 200, 300],\n",
    "    'regressor__learning_rate': [0.01, 0.1],\n",
    "    'regressor__max_depth': [3, 5, 7],\n",
    "    'regressor__min_samples_split': [2, 4],\n",
    "    'regressor__min_samples_leaf': [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search using 5-fold cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation data using the best estimator\n",
    "best_pipeline = grid_search.best_estimator_\n",
    "y_pred = best_pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 714874404.1331942\n",
      "R2: 0.832938374758694\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using R2 and MSE\n",
    "\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61f7c684093ed988e34cfdf7e38e05225137e35d8f6152fffe52ef6df22f9799"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
